---
title: "Weekly Web & Social Media Report"
author: "Press Unit"
output:
  word_document: default
params:
  data: ""
---

<style>
  body {
    text-align: justify
  }
</style>                                                                  

```{r setup, include=FALSE}
pkgs <- c("dplyr", "ggplot2", "knitr", "lubridate")
lapply(pkgs, function(P) 
  suppressPackageStartupMessages(require(P, character.only = TRUE)))

opts_chunk$set(echo = FALSE)
```

```{r initialize, message=FALSE, include=FALSE}
reportPeriodText <- 
  paste(format(today() - 6, "%d %B"), "to", format(today(), "%d %B %Y"))

## TODO: Implement month & year transitions
```

# Overview
**Reporting Period:** `r reportPeriodText`.

## Website

```{r load all data}
newsData <- params$data$webnews
all_twts <- params$data$tweets
all_fbs <- params$data$fbposts
```

```{r website}
newsData$Date <- newsData$Date %>%
  as.Date(origin = "1970-01-01") %>%
  as.POSIXct()

newsData <- newsData %>%
  mutate(Month = format(Date, "%B")) %>%
  mutate(Year = format(Date, "%Y"))

## make variables for monthly/annual data
thisMth <- format(today(), "%B")
thisYr <- format(today(), "%Y")

mth_news <- newsData %>%
  filter(Month == thisMth & Year == thisYr)
wk_news <- newsData %>%
  filter(as.Date(Date) >= today() - 7)

## TODO: Draw plots reflecting activity trend. Roll over a one-year period.
```

| **News Stories** |    **Result**                                |
|------------------|----------------------------------------------|
| All-time         | `r nrow(newsData)`                           |
| In `r thisMth`   | `r nrow(mth_news)`                           |
| Last 7 days      | `r nrow(wk_news)`                            |
| Most recent      | `r newsData$Title[which.max(newsData$Date)]` |
|                  |                                              |


## Twitter
```{r load twitter data, message=FALSE}
## Process tweets
all_twts <- process_stored_tweets(all_twts)

## Add a column of Date objects for easy categorisation. Also carry 
## out a check to see whether the database needs to be updated.
all_twts$date_only <- as.Date(all_twts$created)

wk_data <- all_twts %>%
  filter(date_only >= (today() - 6) & date_only <= (today())) %>%
  arrange(date_only) %>%
  mutate(day = weekdays(date_only, abbreviate = TRUE)) %>%
  mutate(Type = ifelse(isRetweet, "Retweet", "Original"))
wk_data$day <-  factor(wk_data$day,
                       levels = unique(wk_data$day),
                       ordered = TRUE)
  
last_wk <- all_twts %>%
  filter(date_only >= (today() - 13) & date_only <= (today() - 7))

## Remove characters from the text of tweets that are not human-readable, 
## as they would be of no practical use in the analysis.
wk_data$text <- remove_nonreadables(wk_data$text)

## Some objects to be used to generate and/or display statistics
no.wk <- nrow(wk_data)
month_begin <- floor_date(today(), "month")
month_end <- ceiling_date(today(), "month")
mth_data <- filter(all_twts, date_only >= month_begin & date_only <= month_end)
mostRTed <- wk_data$text[which.max(wk_data$retweetCount)]
mostFaved <- wk_data$text[which.max(wk_data$favoriteCount)]
tweets_by_us <- filter(wk_data, screenName == "NESREANigeria")
busiest_day <- which.max(table(wk_data$date_only))
busiest_day <- ymd(names(busiest_day))
```

```{r series-twitter}
A <- "1970-01-01"
thisWk <- as.numeric(format(today(), "%V"))

twtsPerWeek <- all_twts %>% 
  filter(as.Date(as.POSIXct(created, origin = A)) - today() <= 365) %>% 
  mutate(week = as.numeric(format(as.POSIXct(created, origin = A), "%V"))) %>% 
  group_by(week) %>% 
  count() %>% 
  as_tibble() %>% 
  mutate(lag = abs(week - thisWk)) %>% 
  arrange(lag)

plot(ts(twtsPerWeek$n, start = 53 - thisWk), col = "blue", lwd = 2)

```

|     **Description**          |    **Result**                    |
|------------------------------|----------------------------------|
| In `r format(today(), "%B")` | `r nrow(mth_data)`               |
| In last 7 days               | `r no.wk`                        |
| Posts made                   | `r nrow(tweets_by_us)`           |
| Mentions                     | `r nrow(wk_data)`                |
| Daily average                | `r floor(nrow(wk_data)/7)`       |
| Most active on               | `r format(busiest_day, "%d %B")` |
| Most liked                   | `r mostFaved`                    |
| Most retweeted               | `r mostRTed`                     |
| Comparative activity         | **`r no.wk - nrow(last_wk)`**    |
|                              |                                  |

<!-- TODO: Add No. of followers (overall) & new followers (in last 7 days) -->

## Facebook
```{r load-fb-data, message=FALSE}
                        ############
                        # Facebook #
                        ############
## Load data on Facebook Page posts from database;
## also do a little data wrangling
fbPosts <- all_fbs %>%
  prepare_data(.) %>%
  select(message:shares_count) %>%
  mutate(created_mth = format(as.Date(created_time), "%B")) %>%
  mutate(created_yr = format(as.Date(created_time), "%Y"))

fbComments <- params$data$fbcomments
fbLikes <- params$data$fblikes

## Convert to date-time structures
fbPosts$created_time <- as.POSIXct(fbPosts$created_time)
fbComments$created_time <- as.POSIXct(fbComments$created_time)

## Remove any non-humanly readable characters
fbPosts$message <- remove_nonreadables(fbPosts$message)
fbComments$message <- remove_nonreadables(fbComments$message)

fbPosts$created_mth <-
  fbPosts$created_mth %>%
  factor(levels = month.name, ordered = TRUE)

mth_Posts <- fbPosts %>%
  filter(created_mth == thisMth & created_yr == thisYr)
wk_Posts <- mth_Posts %>%
  filter(created_time >= (today() - 6))
```

|     **Description**        |    **Result**                            |
|----------------------------|------------------------------------------|
|NESREA Page Posts (All-time)|`r nrow(fbPosts)`                         |
|Posts in `r thisMth`        |`r nrow(mth_Posts)`                       |
|Posts in the past 7 days    |`r nrow(wk_Posts)`                        |
|Most Liked  (Overall)       |`r return_text(fbPosts, "likes_count")`   |
|Most Liked in `r thisMth`   |`r return_text(mth_Posts, "likes_count")` |
|Most Shared (Overall)       |`r return_text(fbPosts, "shares_count")`  |
|Most Shared in `r thisMth`  |`r return_text(mth_Posts, "shares_count")`|
|Most Commented  (Overall)   |`r return_text(fbPosts, "comments_count")`|
|                            |                                          |

## Website 

```{r news summary, results='asis'}
kable(head(newsData[, c(1, 4, 5)], n = 10L),
             caption = "Table: Ten (10) Most Recently Uploaded News Stories")
```

## Twitter

```{r plain density, warning=FALSE, message=FALSE}
simplePlot <- plain_dens_plot(data = wk_data, platform = "twitter")
simplePlot +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

```{r daily tweets plot}  
simplePlot +
  facet_grid(day ~ .) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

```{r disaggregated tweets density}
ggplot(wk_data, aes(created)) +
  geom_density(aes(fill = Type), alpha = .5) +
  theme(legend.justification = c(1, 1), legend.position = c(1, 1)) +
  ggtitle(paste("Distribution of tweets for", reportPeriodText)) +
  xlab("Date")
```

```{r twitter sentiments dotchart-1}
spl <- split(wk_data, wk_data$isRetweet)
origTwts <- spl[['FALSE']]

twPol <- compute_emotional_valence(origTwts$text)
visualise_pol_diff(pol.list = twPol)
```

```{r twitter sentiment extremes}
origTwts$emotionalValence <- sapply(twPol, function(x) x$all$polarity)
```


* __Most positive tweet__: `r origTwts$text[which.max(origTwts$emotionalValence)]`
* __Most negative tweet__: `r origTwts$text[which.min(origTwts$emotionalValence)]`  

 
```{r, twitter wordcloud}
generate_wordcloud(origTwts, twPol, site = "Twitter")
```

```{r network}
## TODO
RT <- mutate(spl[['TRUE']], sender = substr(text, 5, regexpr(':', text) - 1))
```


## Facebook

```{r density dist: FB posts}
ggplot(fbPosts, aes(created_time)) +
  geom_density(fill = "purple", alpha = 0.6) +
  ggtitle("Distribution of Facebook posts")
```


```{r density dist: FB comments}
plain_dens_plot(fbComments, platform = "facebook")
```
 
```{r fb polarities}
fbPol <- compute_emotional_valence(text.var = fbComments$message)
visualise_pol_diff(pol.list = fbPol)
```
  
```{r facebook wordcloud}
fbComments$emotionalValence <- sapply(fbPol, function(x) x$all$polarity)
generate_wordcloud(fbComments, fbPol, site = "Facebook")
```
